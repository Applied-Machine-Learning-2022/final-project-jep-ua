{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDMX5V/7sk25MCihTjUWtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Applied-Machine-Learning-2022/final-project-jep-ua/blob/main/Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract==0.3.9 \n",
        "!pip install imutils\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q6idzHyT4Oe0",
        "outputId": "6ab7b7c8-0dbd-422a-b849-e542819da874"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 5s (906 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract==0.3.9\n",
            "  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract==0.3.9) (21.3)\n",
            "Collecting Pillow>=8.0.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract==0.3.9) (3.0.9)\n",
            "Installing collected packages: Pillow, pytesseract\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.2.0 pytesseract-0.3.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (9.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the data to train the model\n",
        "! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d andrewmvd/car-plate-detection\n",
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuezNDk97Nwc",
        "outputId": "f21a3eea-e34c-49ad-bf56-a34cbacba4fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading car-plate-detection.zip to /content\n",
            " 99% 201M/203M [00:01<00:00, 168MB/s]\n",
            "100% 203M/203M [00:01<00:00, 124MB/s]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('car-plate-detection.zip','r') as z:\n",
        "  z.extractall('./')\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cZuzs4iBBPo",
        "outputId": "60966044-34c0-4cf1-bad7-f92e679d7372"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'images',\n",
              " 'annotations',\n",
              " '.ipynb_checkpoints',\n",
              " 'car-plate-detection.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "(train_images, train_labels), (test_images, test_labels) = \n",
        "\n"
      ],
      "metadata": {
        "id": "LEE0Y2PCAfqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  \".\",\n",
        "  validation_split=0.3,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  batch_size=32,\n",
        "  shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "for image_batch, labels_batch in ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9cmpUAgIWP9",
        "outputId": "b1c2676c-2a5b-411d-e5cd-2640ce0fc0e4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 433 files belonging to 5 classes.\n",
            "Using 304 files for training.\n",
            "(32, 256, 256, 3)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "433 * 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9OTRt_4JxTU",
        "outputId": "60424113-b4d9-4f8b-92a1-73245ad8656f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303.09999999999997"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "s = set()\n",
        "for i in range(433):\n",
        "  s.add(cv2.imread(\"images/Cars{}.png\".format(i)).shape)\n",
        "\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzNHLflIdqf",
        "outputId": "5b6168b9-58d1-4570-f606-3d5a856ac449"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(141, 400, 3),\n",
              " (151, 400, 3),\n",
              " (176, 400, 3),\n",
              " (185, 400, 3),\n",
              " (190, 400, 3),\n",
              " (192, 400, 3),\n",
              " (196, 400, 3),\n",
              " (197, 400, 3),\n",
              " (198, 400, 3),\n",
              " (200, 400, 3),\n",
              " (201, 400, 3),\n",
              " (204, 400, 3),\n",
              " (205, 400, 3),\n",
              " (209, 400, 3),\n",
              " (210, 400, 3),\n",
              " (215, 400, 3),\n",
              " (218, 400, 3),\n",
              " (220, 415, 3),\n",
              " (221, 400, 3),\n",
              " (223, 300, 3),\n",
              " (225, 300, 3),\n",
              " (225, 400, 3),\n",
              " (226, 400, 3),\n",
              " (227, 323, 3),\n",
              " (229, 558, 3),\n",
              " (230, 400, 3),\n",
              " (232, 500, 3),\n",
              " (233, 400, 3),\n",
              " (234, 500, 3),\n",
              " (238, 400, 3),\n",
              " (240, 400, 3),\n",
              " (242, 400, 3),\n",
              " (242, 431, 3),\n",
              " (243, 400, 3),\n",
              " (244, 400, 3),\n",
              " (245, 400, 3),\n",
              " (246, 400, 3),\n",
              " (247, 400, 3),\n",
              " (248, 400, 3),\n",
              " (250, 400, 3),\n",
              " (251, 400, 3),\n",
              " (253, 400, 3),\n",
              " (255, 400, 3),\n",
              " (256, 400, 3),\n",
              " (259, 400, 3),\n",
              " (260, 320, 3),\n",
              " (260, 400, 3),\n",
              " (262, 400, 3),\n",
              " (262, 508, 3),\n",
              " (263, 350, 3),\n",
              " (265, 400, 3),\n",
              " (266, 400, 3),\n",
              " (267, 400, 3),\n",
              " (268, 400, 3),\n",
              " (268, 500, 3),\n",
              " (270, 400, 3),\n",
              " (270, 450, 3),\n",
              " (270, 471, 3),\n",
              " (275, 553, 3),\n",
              " (276, 320, 3),\n",
              " (279, 400, 3),\n",
              " (281, 400, 3),\n",
              " (284, 400, 3),\n",
              " (286, 430, 3),\n",
              " (288, 400, 3),\n",
              " (290, 400, 3),\n",
              " (290, 435, 3),\n",
              " (291, 400, 3),\n",
              " (292, 400, 3),\n",
              " (295, 400, 3),\n",
              " (299, 400, 3),\n",
              " (299, 450, 3),\n",
              " (300, 400, 3),\n",
              " (300, 467, 3),\n",
              " (300, 500, 3),\n",
              " (301, 400, 3),\n",
              " (303, 517, 3),\n",
              " (305, 400, 3),\n",
              " (307, 400, 3),\n",
              " (314, 236, 3),\n",
              " (315, 560, 3),\n",
              " (318, 400, 3),\n",
              " (319, 400, 3),\n",
              " (320, 400, 3),\n",
              " (331, 585, 3),\n",
              " (331, 586, 3),\n",
              " (332, 400, 3),\n",
              " (332, 443, 3),\n",
              " (333, 442, 3),\n",
              " (338, 600, 3),\n",
              " (342, 400, 3),\n",
              " (343, 590, 3),\n",
              " (350, 590, 3),\n",
              " (353, 400, 3),\n",
              " (354, 400, 3),\n",
              " (360, 480, 3),\n",
              " (365, 500, 3),\n",
              " (367, 400, 3),\n",
              " (367, 550, 3),\n",
              " (374, 500, 3),\n",
              " (375, 500, 3),\n",
              " (375, 600, 3),\n",
              " (380, 500, 3),\n",
              " (388, 507, 3),\n",
              " (398, 530, 3),\n",
              " (399, 600, 3),\n",
              " (400, 225, 3),\n",
              " (400, 240, 3),\n",
              " (400, 282, 3),\n",
              " (400, 300, 3),\n",
              " (400, 301, 3),\n",
              " (400, 370, 3),\n",
              " (400, 386, 3),\n",
              " (400, 399, 3),\n",
              " (400, 400, 3),\n",
              " (400, 500, 3),\n",
              " (400, 600, 3),\n",
              " (411, 600, 3),\n",
              " (416, 555, 3),\n",
              " (417, 600, 3),\n",
              " (420, 560, 3),\n",
              " (422, 457, 3),\n",
              " (424, 520, 3),\n",
              " (425, 600, 3),\n",
              " (450, 600, 3),\n",
              " (478, 400, 3),\n",
              " (500, 375, 3),\n",
              " (531, 600, 3)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "image = cv2.imread(\"license_plate.jpg\")\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"/usr/bin/tesseract\" #r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# Grayscale, Gaussian blur, Otsu's threshold\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "# Morph open to remove noise and invert image\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "invert = 255 - opening\n",
        "\n",
        "# Perform text extraction\n",
        "data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "print(data)\n",
        "\n",
        "cv2.imwrite(\"thresh.jpg\", thresh)\n",
        "# cv2.imshow('thresh', thresh)\n",
        "# cv2.imshow('opening', opening)\n",
        "# cv2.imshow('invert', invert)\n",
        "cv2.waitKey()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKXm5vBcgHdl",
        "outputId": "1baf115c-aaaa-4989-8024-4223b657df93"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "» * Arkansas’ ii\n",
            "514 KZE\n",
            "\f\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! which tesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQpsL-TGgms1",
        "outputId": "a2ca3a76-f56c-4ae6-b1a1-571cd6ff0e56"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/tesseract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5GaGturVm-79"
      },
      "outputs": [],
      "source": [
        "#read in frames\n",
        "# import cv2 as cv\n",
        "# import pytesseract\n",
        "# cars_video = cv.VideoCapture('cars.mp4')\n",
        "\n",
        "\n",
        "# height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "# width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "# fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "# total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# cars_video = cv.VideoCapture('cars.mp4')\n",
        "\n",
        "# total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# frames_read = 0\n",
        "\n",
        "# for current_frame in range(0, total_frames):\n",
        "#   cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "#   ret, _ = cars_video.read()\n",
        "#   if not ret:\n",
        "#     raise Exception(f'Problem reading frame {current_frame} from video')\n",
        "#   if (current_frame+1) % 50 == 0:\n",
        "#     print(f'Read {current_frame+1} frames so far')\n",
        "\n",
        "# cars_video.release()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "# image = cv.imread(\"license_plate.jpg\")\n",
        "\n",
        "# image = Image.open(\"HT_ArkansasTag.png\")\n",
        "# image = Image.new(\"P\", (100, 100))\n",
        "# image= np.zeros((1, 1, 100))\n",
        "# pytesseract.image_to_string(image)\n",
        "\n",
        "# import cv2\n",
        "# image = cv2.imread(\"HT_ArkansasTag.png\")\n",
        "# image = cv2.resize(image, (600, 360))\n",
        "# words = pytesseract.image_to_string(image)\n",
        "# image.shape\n",
        "# print(words)\n",
        "\n",
        "# gray_image = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# gray_image = cv2.bilateralFilter(gray_image,11,17,17)\n",
        "\n",
        "# edged = cv2.Canny(gray_image,30,200)\n",
        "# cnts,new = cv2.findContours(edged.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
        "# # image = Image.open(\"license_plate.jpg\")\n",
        "# cnts = sorted(cnts,key = cv2.contourArea,reverse = True) [:30]\n",
        "# screenCnt = None\n",
        "\n",
        "# #Finding the contour with four sides\n",
        "# i=7\n",
        "# for c in cnts:\n",
        "#   perimeter = cv2.arcLength(c,True)\n",
        "#   approx = cv2.approxPolyDP(c,0.018*perimeter,True)\n",
        "#   if len(approx)==4:\n",
        "#     screenCnt = approx\n",
        "\n",
        "# x,y,w,h = cv2.boundingRect(c)\n",
        "# new_img = image[y:y+h,x:x+w]\n",
        "# cv2.imwrite('./'+str(i)+'.png',new_img)\n",
        "\n",
        "image = cv2.imread(\"license_plate.jpg\")\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# Grayscale, Gaussian blur, Otsu's threshold\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "# Morph open to remove noise and invert image\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "invert = 255 - opening\n",
        "\n",
        "# Perform text extraction\n",
        "data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "print(data)\n",
        "\n",
        "cv2.imwrite(\"thresh.jpg\", thresh)\n",
        "# cv2.imshow('thresh', thresh)\n",
        "# cv2.imshow('opening', opening)\n",
        "# cv2.imshow('invert', invert)\n",
        "cv2.waitKey()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "aTyHKlgN39_m",
        "outputId": "b16c6146-d1e4-4f9a-c125-c6052471514e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TesseractNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe': 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-327a3151c02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Perform text extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--psm 6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     }[output_type]()\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     }[output_type]()\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    284\u001b[0m         }\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_filename_base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m: C:\\Program Files\\Tesseract-OCR\\tesseract.exe is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "file_name = 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz'\n",
        "\n",
        "url = base_url + file_name\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "dir_name = file_name[0:-len('.tar.gz')]\n",
        "\n",
        "if os.path.exists(dir_name):\n",
        "  shutil.rmtree(dir_name) \n",
        "\n",
        "tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "\n",
        "os.listdir(dir_name)\n",
        "\n",
        "frozen_graph = os.path.join(dir_name, 'frozen_inference_graph.pb')\n",
        "\n",
        "with tf.io.gfile.GFile(frozen_graph, \"rb\") as f:\n",
        "  graph_def = tf.compat.v1.GraphDef()\n",
        "  loaded = graph_def.ParseFromString(f.read())\n",
        "\n",
        "cars_video = cv.VideoCapture('cars.mp4')\n",
        "height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "frames_read = 0\n",
        "\n",
        "r = 255\n",
        "g = 0\n",
        "b = 0\n",
        "scale = .5\n",
        "thickness = 1\n",
        "\n",
        "outputs = (\n",
        "  'num_detections:0',\n",
        "  'detection_classes:0',\n",
        "  'detection_scores:0',\n",
        "  'detection_boxes:0',\n",
        ")\n",
        "\n",
        "def wrap_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "  wrapped = tf.compat.v1.wrap_function(\n",
        "    lambda: tf.compat.v1.import_graph_def(graph_def, name=\"\"), [])\n",
        "\n",
        "  return wrapped.prune(\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n",
        "\n",
        "\n",
        "model = wrap_graph(graph_def=graph_def,\n",
        "                   inputs=[\"image_tensor:0\"],\n",
        "                   outputs=outputs)\n",
        "model.outputs\n",
        "\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "while (True):\n",
        "  # cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "  ret, image = cars_video.read()\n",
        "  if (not ret):\n",
        "    break \n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "  h, w, _ = image.shape\n",
        "  input_images = [image]\n",
        "  tensor = tf.convert_to_tensor(input_images, dtype=tf.uint8)\n",
        "\n",
        "  detections = model(tensor)\n",
        "\n",
        "  for i, box in enumerate(detections[3][0]):\n",
        "    if detections[1][0][i] == 18:\n",
        "       x1, y1, x2, y2 = int(box[1]*w), int(box[0]*h), int(box[3]*w), int(box[2]*h)\n",
        "       car = image[y1:y2, x1:x2]\n",
        "\n",
        "       gray = cv2.cvtColor(car, cv2.COLOR_RGB2GRAY)\n",
        "       blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "       thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "       \n",
        "       # Morph open to remove noise and invert image\n",
        "       kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "       opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "       invert = 255 - opening\n",
        "       \n",
        "       # Perform text extraction\n",
        "       data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "       if data ==[]:\n",
        "         continue\n",
        "       else:\n",
        "        print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8fgNAdVBjn3",
        "outputId": "0c74227a-6add-4e3e-f6f7-7e2b146d502a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('License-Plate-Recognition-master.zip','r') as z:\n",
        "  z.extractall('./')\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiEJP3Ef7oJo",
        "outputId": "9ba07177-76b9-4801-eefd-3685be9e7759"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'License-Plate-Recognition-master.zip',\n",
              " 'predict.py',\n",
              " 'License-Plate-Recognition-master',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd License-Plate-Recognition-master; python predict.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34m0cFmJaYv",
        "outputId": "fdb0c09a-fa98-40e9-af4c-f477f18da836"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"predict.py\", line 544, in <module>\n",
            "    r, roi, color = c.predict(\"2.jpg\")\n",
            "  File \"predict.py\", line 245, in predict\n",
            "    img = imreadex(car_pic)\n",
            "  File \"predict.py\", line 14, in imreadex\n",
            "    return cv2.imdecode(np.fromfile(filename, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '2.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/License-Plate-Recognition-master\")\n",
        "from predict import *"
      ],
      "metadata": {
        "id": "oc4eOeDdKF-6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV26hnqXfiCn",
        "outputId": "331e2f2c-182c-4aed-b7be-fac38059709a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car.jpeg     License-Plate-Recognition-master\t   __pycache__\n",
            "images.jpeg  License-Plate-Recognition-master.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from predict import *\n",
        "from google.colab.patches import cv2_imshow\n",
        "c = CardPredictor()\n",
        "gray_img = c.predict('/content/License-Plate-Recognition-master/test/car5.jpg')\n",
        "# cv2_imshow('ec.png', plate_img[1])\n",
        "# cv2_imshow(plate_img[1])\n",
        "# plate_img[3].shape\n",
        "import matplotlib.pyplot as plt\n",
        "cv2_imshow(gray_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XXo8xO8efERM",
        "outputId": "b5acf129-5066-4a71-b69a-772eadf68091"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h,w: 300 521\n",
            "len(contours) 3\n",
            "2\n",
            "精确定位\n",
            "blue\n",
            "3413 136 16 642 0 4418\n",
            "no\n",
            "4188 98 86 520 306 22599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function CardPredictor.__del__ at 0x7f33d736add0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/License-Plate-Recognition-master/predict.py\", line 147, in __del__\n",
            "  File \"/content/License-Plate-Recognition-master/predict.py\", line 202, in save_traindata\n",
            "AttributeError: 'CardPredictor' object has no attribute 'model'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=85x33 at 0x7F33D6C5FB90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFUAAAAhCAAAAACNLbhRAAABSElEQVR4nK2WSRbEIAhEKV/uf2V6YSJTqRmaTdI2fgtEDOQ/pu4dgn+hgr2gTlkXTvfUFUNEoFKl6fEE4fSsPfAZxOLFTN/thGvw7WuMDCA6PrIi93gia45SDD0KkSZgaYkrqfL3k+MeTmu1yPTC1I8Ob02DrSKTmiCmZFxLAuGpIcq6VJy1GzuMww9aPzsmeF26pzWvU7nQvHl7a+c08U9igNyXeua1V9enrhisUzXFnrOgqrQu19S1xbRPuS4/gwr7L1vKDPHIQxd1edc86V+i4jOwvThEhDUNNv+iztOV6LizY363XNmyibsbzD37ibV7ZlPozEFPFmzlfc/yYuhpJj+bLbcI0UIpPojwvp28axOmiUpdA6TXNTKNaKmysKq2ZhNGtqOXYwFYFKwz17WNEj89XrSyFvWU8LZGK2Y0lbcfBcKC+QETaWZL8SUl7QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract==0.3.9 \n",
        "!pip install imutils\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBCCaI-UKVdb",
        "outputId": "3126f687-e10f-417e-db71-3012f6212aa6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract==0.3.9 in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract==0.3.9) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract==0.3.9) (9.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract==0.3.9) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (9.2.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Code\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from numpy.linalg import norm\n",
        "import sys\n",
        "import  os\n",
        "import json\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "SZ  =  20           #training picture length and width\n",
        "MAX_WIDTH  =  1000 #Original  image maximum width\n",
        "Min_Area  =  2000 #The   maximum allowable area of ​​the license plate area\n",
        "PROVINCE_START = 1000\n",
        "\n",
        "\n",
        "base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "file_name = 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz'\n",
        "\n",
        "url = base_url + file_name\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "dir_name = file_name[0:-len('.tar.gz')]\n",
        "\n",
        "if os.path.exists(dir_name):\n",
        "  shutil.rmtree(dir_name) \n",
        "\n",
        "tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "\n",
        "os.listdir(dir_name)\n",
        "\n",
        "frozen_graph = os.path.join(dir_name, 'frozen_inference_graph.pb')\n",
        "\n",
        "with tf.io.gfile.GFile(frozen_graph, \"rb\") as f:\n",
        "  graph_def = tf.compat.v1.GraphDef()\n",
        "  loaded = graph_def.ParseFromString(f.read())\n",
        "\n",
        "cars_video = cv2.VideoCapture('cars.mp4')\n",
        "height = int(cars_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cars_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "fps = cars_video.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cars_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "frames_read = 0\n",
        "\n",
        "r = 255\n",
        "g = 0\n",
        "b = 0\n",
        "scale = .5\n",
        "thickness = 1\n",
        "\n",
        "outputs = (\n",
        "  'num_detections:0',\n",
        "  'detection_classes:0',\n",
        "  'detection_scores:0',\n",
        "  'detection_boxes:0',\n",
        ")\n",
        "\n",
        "def wrap_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "  wrapped = tf.compat.v1.wrap_function(\n",
        "    lambda: tf.compat.v1.import_graph_def(graph_def, name=\"\"), [])\n",
        "\n",
        "  return wrapped.prune(\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n",
        "\n",
        "\n",
        "model = wrap_graph(graph_def=graph_def,\n",
        "                   inputs=[\"image_tensor:0\"],\n",
        "                   outputs=outputs)\n",
        "model.outputs\n",
        "\n",
        "\n",
        "def point_limit(point):\n",
        "    if point[0] < 0:\n",
        "        point[0] = 0\n",
        "    if point[1] < 0:\n",
        "        point[1] = 0\n",
        "\n",
        "\n",
        "def accurate_place(card_img_hsv, limit1, limit2, color):\n",
        "    row_num, col_num = card_img_hsv.shape[:2]\n",
        "    xl = col_num\n",
        "    xr = 0\n",
        "    yh = 0\n",
        "    yl = row_num\n",
        "    #col_num_limit = self.cfg[\"col_num_limit\"]\n",
        "    row_num_limit = 18\n",
        "    col_num_limit = col_num * 0.8 if color != \"green\" else col_num * 0.5#绿色有渐变\n",
        "    for i in range(row_num):\n",
        "        count = 0\n",
        "        for j in range(col_num):\n",
        "            H = card_img_hsv.item(i, j, 0)\n",
        "            S = card_img_hsv.item(i, j, 1)\n",
        "            V = card_img_hsv.item(i, j, 2)\n",
        "            if limit1 < H <= limit2 and 34 < S and 46 < V:\n",
        "                count += 1\n",
        "        if count > col_num_limit:\n",
        "            if yl > i:\n",
        "                yl = i\n",
        "            if yh < i:\n",
        "                yh = i\n",
        "    for j in range(col_num):\n",
        "        count = 0\n",
        "        for i in range(row_num):\n",
        "            H = card_img_hsv.item(i, j, 0)\n",
        "            S = card_img_hsv.item(i, j, 1)\n",
        "            V = card_img_hsv.item(i, j, 2)\n",
        "            if limit1 < H <= limit2 and 34 < S and 46 < V:\n",
        "                count += 1\n",
        "        if count > row_num - row_num_limit:\n",
        "            if xl > j:\n",
        "                xl = j\n",
        "            if xr < j:\n",
        "                xr = j\n",
        "    return xl, xr, yh, yl\n",
        "\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "for i in range(0, int(cars_video.get(cv2.CAP_PROP_FRAME_COUNT)),50):\n",
        "  # cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "  ret, img = cars_video.read()\n",
        "  # img = cv2.imread(\"/content/License-Plate-Recognition-master/test/car5.jpg\")\n",
        "  if (not ret):\n",
        "    break \n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  h, w, _ = img.shape\n",
        "  input_images = [img]\n",
        "  tensor = tf.convert_to_tensor(input_images, dtype=tf.uint8)\n",
        "\n",
        "  detections = model(tensor)\n",
        "  # print(detections)\n",
        "  for i, box in enumerate(detections[3][0]):\n",
        "    if True:\n",
        "        img = cv2.imread(\"/content/License-Plate-Recognition-master/test/car5.jpg\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        pic_hight, pic_width = img.shape[:2]\n",
        "        if pic_width > MAX_WIDTH:\n",
        "            pic_rate = MAX_WIDTH / pic_width\n",
        "            img = cv2.resize(img, (MAX_WIDTH, int(pic_hight*pic_rate)), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "        print(\"h,w:\", pic_hight, pic_width)\n",
        "        blur = 3\n",
        "        #高斯去噪\n",
        "        if blur > 0:\n",
        "            img = cv2.GaussianBlur(img, (blur, blur), 0)#图片分辨率调整\n",
        "        oldimg = img\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        kernel = np.ones((20, 20), np.uint8)\n",
        "        img_opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "        img_opening = cv2.addWeighted(img, 1, img_opening, -1, 0);\n",
        "\n",
        "        #找到图像边缘\n",
        "        ret, img_thresh = cv2.threshold(img_opening, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        img_edge = cv2.Canny(img_thresh, 100, 200)\n",
        "        #使用开运算和闭运算让图像边缘成为一个整体\n",
        "        kernel = np.ones((5, 12), np.uint8)\n",
        "        img_edge1 = cv2.morphologyEx(img_edge, cv2.MORPH_CLOSE, kernel)\n",
        "        img_edge2 = cv2.morphologyEx(img_edge1, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        #查找图像边缘整体形成的矩形区域，可能有很多，车牌就在其中一个矩形区域中\n",
        "        try:\n",
        "            contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        except ValueError:\n",
        "            image, contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        contours = [cnt for cnt in contours if cv2.contourArea(cnt) > Min_Area]\n",
        "        print('len(contours)', len(contours))\n",
        "        #一一排除不是车牌的矩形区域\n",
        "        car_contours = []\n",
        "        for cnt in contours:\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            area_width, area_height = rect[1]\n",
        "            if area_width < area_height:\n",
        "                area_width, area_height = area_height, area_width\n",
        "            wh_ratio = area_width / area_height\n",
        "            #print(wh_ratio)\n",
        "            #要求矩形区域长宽比在2到5.5之间，2到5.5是车牌的长宽比，其余的矩形排除\n",
        "            if wh_ratio > 2 and wh_ratio < 5.5:\n",
        "                car_contours.append(rect)\n",
        "                box = cv2.boxPoints(rect)\n",
        "                box = np.int0(box)\n",
        "                #oldimg = cv2.drawContours(oldimg, [box], 0, (0, 0, 255), 2)\n",
        "                #cv2.imshow(\"edge4\", oldimg)\n",
        "                #cv2.waitKey(0)\n",
        "\n",
        "        print(len(car_contours))\n",
        "\n",
        "        print(\"精确定位\")\n",
        "        card_imgs = []\n",
        "        #矩形区域可能是倾斜的矩形，需要矫正，以便使用颜色定位\n",
        "        for rect in car_contours:\n",
        "            if rect[2] > -1 and rect[2] < 1:#创造角度，使得左、高、右、低拿到正确的值\n",
        "                angle = 1\n",
        "            else:\n",
        "                angle = rect[2]\n",
        "            rect = (rect[0], (rect[1][0]+5, rect[1][1]+5), angle)#扩大范围，避免车牌边缘被排除\n",
        "\n",
        "            box = cv2.boxPoints(rect)\n",
        "            heigth_point = right_point = [0, 0]\n",
        "            left_point = low_point = [pic_width, pic_hight]\n",
        "            for point in box:\n",
        "                if left_point[0] > point[0]:\n",
        "                    left_point = point\n",
        "                if low_point[1] > point[1]:\n",
        "                    low_point = point\n",
        "                if heigth_point[1] < point[1]:\n",
        "                    heigth_point = point\n",
        "                if right_point[0] < point[0]:\n",
        "                    right_point = point\n",
        "\n",
        "            if left_point[1] <= right_point[1]:#正角度\n",
        "                new_right_point = [right_point[0], heigth_point[1]]\n",
        "                pts2 = np.float32([left_point, heigth_point, new_right_point])#字符只是高度需要改变\n",
        "                pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "                M = cv2.getAffineTransform(pts1, pts2)\n",
        "                dst = cv2.warpAffine(oldimg, M, (pic_width, pic_hight))\n",
        "                point_limit(new_right_point)\n",
        "                point_limit(heigth_point)\n",
        "                point_limit(left_point)\n",
        "                card_img = dst[int(left_point[1]):int(heigth_point[1]), int(left_point[0]):int(new_right_point[0])]\n",
        "                card_imgs.append(card_img)\n",
        "                #cv2.imshow(\"card\", card_img)\n",
        "                #cv2.waitKey(0)\n",
        "            elif left_point[1] > right_point[1]:#负角度\n",
        "                \n",
        "                new_left_point = [left_point[0], heigth_point[1]]\n",
        "                pts2 = np.float32([new_left_point, heigth_point, right_point])#字符只是高度需要改变\n",
        "                pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "                M = cv2.getAffineTransform(pts1, pts2)\n",
        "                dst = cv2.warpAffine(oldimg, M, (pic_width, pic_hight))\n",
        "                point_limit(right_point)\n",
        "                point_limit(heigth_point)\n",
        "                point_limit(new_left_point)\n",
        "                card_img = dst[int(right_point[1]):int(heigth_point[1]), int(new_left_point[0]):int(right_point[0])]\n",
        "                card_imgs.append(card_img)\n",
        "                #cv2.imshow(\"card\", card_img)\n",
        "                #cv2.waitKey(0)\n",
        "        #开始使用颜色定位，排除不是车牌的矩形，目前只识别蓝、绿、黄车牌\n",
        "        colors = []\n",
        "        for card_index,card_img in enumerate(card_imgs):\n",
        "            green = yello = blue = black = white = 0\n",
        "            card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "            #有转换失败的可能，原因来自于上面矫正矩形出错\n",
        "            if card_img_hsv is None:\n",
        "                continue\n",
        "            row_num, col_num= card_img_hsv.shape[:2]\n",
        "            card_img_count = row_num * col_num\n",
        "\n",
        "            for i in range(row_num):\n",
        "                for j in range(col_num):\n",
        "                    H = card_img_hsv.item(i, j, 0)\n",
        "                    S = card_img_hsv.item(i, j, 1)\n",
        "                    V = card_img_hsv.item(i, j, 2)\n",
        "                    if 11 < H <= 34 and S > 34:#图片分辨率调整\n",
        "                        yello += 1\n",
        "                    elif 35 < H <= 99 and S > 34:#图片分辨率调整\n",
        "                        green += 1\n",
        "                    elif 99 < H <= 124 and S > 34:#图片分辨率调整\n",
        "                        blue += 1\n",
        "                    \n",
        "                    if 0 < H <180 and 0 < S < 255 and 0 < V < 46:\n",
        "                        black += 1\n",
        "                    elif 0 < H <180 and 0 < S < 43 and 221 < V < 225:\n",
        "                        white += 1\n",
        "            color = \"no\"\n",
        "\n",
        "            limit1 = limit2 = 0\n",
        "            if yello*2 >= card_img_count:\n",
        "                color = \"yello\"\n",
        "                limit1 = 11\n",
        "                limit2 = 34#有的图片有色偏偏绿\n",
        "            elif green*2 >= card_img_count:\n",
        "                color = \"green\"\n",
        "                limit1 = 35\n",
        "                limit2 = 99\n",
        "            elif blue*2 >= card_img_count:\n",
        "                color = \"blue\"\n",
        "                limit1 = 100\n",
        "                limit2 = 124#有的图片有色偏偏紫\n",
        "            elif black + white >= card_img_count*0.7:#TODO\n",
        "                color = \"bw\"\n",
        "            print(color)\n",
        "            colors.append(color)\n",
        "            print(blue, green, yello, black, white, card_img_count)\n",
        "            #cv2.imshow(\"color\", card_img)\n",
        "            #cv2.waitKey(0)\n",
        "            if limit1 == 0:\n",
        "                continue\n",
        "            #以上为确定车牌颜色\n",
        "            #以下为根据车牌颜色再定位，缩小边缘非车牌边界\n",
        "            xl, xr, yh, yl = accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "            if yl == yh and xl == xr:\n",
        "                continue\n",
        "            need_accurate = False\n",
        "            if yl >= yh:\n",
        "                yl = 0\n",
        "                yh = row_num\n",
        "                need_accurate = True\n",
        "            if xl >= xr:\n",
        "                xl = 0\n",
        "                xr = col_num\n",
        "                need_accurate = True\n",
        "            card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "            if need_accurate:#可能x或y方向未缩小，需要再试一次\n",
        "                card_img = card_imgs[card_index]\n",
        "                card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "                xl, xr, yh, yl = accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "                if yl == yh and xl == xr:\n",
        "                    continue\n",
        "                if yl >= yh:\n",
        "                    yl = 0\n",
        "                    yh = row_num\n",
        "                if xl >= xr:\n",
        "                    xl = 0\n",
        "                    xr = col_num\n",
        "            card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "        #以上为车牌定位\n",
        "        #以下为识别车牌中的字符\n",
        "        predict_result = []\n",
        "        roi = None\n",
        "        card_color = None\n",
        "        for i, color in enumerate(colors):\n",
        "            if color in (\"blue\", \"yello\", \"green\"):\n",
        "                card_img = card_imgs[i]\n",
        "                gray_img = cv2.cvtColor(card_img, cv2.COLOR_BGR2GRAY)\n",
        "                #黄、绿车牌字符比背景暗、与蓝车牌刚好相反，所以黄、绿车牌需要反向\n",
        "                if color == \"green\" or color == \"yello\":\n",
        "                    gray_img = cv2.bitwise_not(gray_img)\n",
        "                ret, gray_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        \n",
        "        car_license_plate = gray_img\n",
        "        cv2_imshow(gray_img)\n",
        "        # gray = cv2.cvtColor(car_license_plate, cv2.COLOR_RGB2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray_img, (3,3), 0)\n",
        "        thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        \n",
        "        # Morph open to remove noise and invert image\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "        invert = 255 - opening\n",
        "        cv2_imshow(invert)\n",
        "        # Perform text extraction\n",
        "        data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "        if data ==[]:\n",
        "            continue\n",
        "        else:\n",
        "          print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "uCSKP1DLb0k9",
        "outputId": "047460f4-74f0-4fdc-fd7d-a3e72ab336f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h,w: 300 521\n",
            "len(contours) 1\n",
            "0\n",
            "精确定位\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-92f68d7c44ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mcar_license_plate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# gray = cv2.cvtColor(car_license_plate, cv2.COLOR_RGB2GRAY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gray_img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/content/License-Plate-Recognition-master/test/car5.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "pic_hight, pic_width = img.shape[:2]\n",
        "if pic_width > MAX_WIDTH:\n",
        "    pic_rate = MAX_WIDTH / pic_width\n",
        "    img = cv2.resize(img, (MAX_WIDTH, int(pic_hight*pic_rate)), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "print(\"h,w:\", pic_hight, pic_width)\n",
        "blur = 3\n",
        "#高斯去噪\n",
        "if blur > 0:\n",
        "    img = cv2.GaussianBlur(img, (blur, blur), 0)#图片分辨率调整\n",
        "oldimg = img\n",
        "kernel = np.ones((20, 20), np.uint8)\n",
        "img_opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "img_opening = cv2.addWeighted(img, 1, img_opening, -1, 0);\n",
        "\n",
        "#找到图像边缘\n",
        "ret, img_thresh = cv2.threshold(img_opening, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "img_edge = cv2.Canny(img_thresh, 100, 200)\n",
        "#使用开运算和闭运算让图像边缘成为一个整体\n",
        "kernel = np.ones((5, 12), np.uint8)\n",
        "img_edge1 = cv2.morphologyEx(img_edge, cv2.MORPH_CLOSE, kernel)\n",
        "img_edge2 = cv2.morphologyEx(img_edge1, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "#查找图像边缘整体形成的矩形区域，可能有很多，车牌就在其中一个矩形区域中\n",
        "try:\n",
        "    contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "except ValueError:\n",
        "    image, contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contours = [cnt for cnt in contours if cv2.contourArea(cnt) > Min_Area]\n",
        "print('len(contours)', len(contours))\n",
        "#一一排除不是车牌的矩形区域\n",
        "car_contours = []\n",
        "for cnt in contours:\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    area_width, area_height = rect[1]\n",
        "    if area_width < area_height:\n",
        "        area_width, area_height = area_height, area_width\n",
        "    wh_ratio = area_width / area_height\n",
        "    #print(wh_ratio)\n",
        "    #要求矩形区域长宽比在2到5.5之间，2到5.5是车牌的长宽比，其余的矩形排除\n",
        "    if wh_ratio > 2 and wh_ratio < 5.5:\n",
        "        car_contours.append(rect)\n",
        "        box = cv2.boxPoints(rect)\n",
        "        box = np.int0(box)\n",
        "        #oldimg = cv2.drawContours(oldimg, [box], 0, (0, 0, 255), 2)\n",
        "        #cv2.imshow(\"edge4\", oldimg)\n",
        "        #cv2.waitKey(0)\n",
        "\n",
        "print(len(car_contours))\n",
        "\n",
        "print(\"精确定位\")\n",
        "card_imgs = []\n",
        "#矩形区域可能是倾斜的矩形，需要矫正，以便使用颜色定位\n",
        "for rect in car_contours:\n",
        "    if rect[2] > -1 and rect[2] < 1:#创造角度，使得左、高、右、低拿到正确的值\n",
        "        angle = 1\n",
        "    else:\n",
        "        angle = rect[2]\n",
        "    rect = (rect[0], (rect[1][0]+5, rect[1][1]+5), angle)#扩大范围，避免车牌边缘被排除\n",
        "\n",
        "    box = cv2.boxPoints(rect)\n",
        "    heigth_point = right_point = [0, 0]\n",
        "    left_point = low_point = [pic_width, pic_hight]\n",
        "    for point in box:\n",
        "        if left_point[0] > point[0]:\n",
        "            left_point = point\n",
        "        if low_point[1] > point[1]:\n",
        "            low_point = point\n",
        "        if heigth_point[1] < point[1]:\n",
        "            heigth_point = point\n",
        "        if right_point[0] < point[0]:\n",
        "            right_point = point\n",
        "\n",
        "    if left_point[1] <= right_point[1]:#正角度\n",
        "        new_right_point = [right_point[0], heigth_point[1]]\n",
        "        pts2 = np.float32([left_point, heigth_point, new_right_point])#字符只是高度需要改变\n",
        "        pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "        M = cv2.getAffineTransform(pts1, pts2)\n",
        "        dst = cv2.warpAffine(oldimg, M, (pic_width, pic_hight))\n",
        "        point_limit(new_right_point)\n",
        "        point_limit(heigth_point)\n",
        "        point_limit(left_point)\n",
        "        card_img = dst[int(left_point[1]):int(heigth_point[1]), int(left_point[0]):int(new_right_point[0])]\n",
        "        card_imgs.append(card_img)\n",
        "        #cv2.imshow(\"card\", card_img)\n",
        "        #cv2.waitKey(0)\n",
        "    elif left_point[1] > right_point[1]:#负角度\n",
        "        \n",
        "        new_left_point = [left_point[0], heigth_point[1]]\n",
        "        pts2 = np.float32([new_left_point, heigth_point, right_point])#字符只是高度需要改变\n",
        "        pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "        M = cv2.getAffineTransform(pts1, pts2)\n",
        "        dst = cv2.warpAffine(oldimg, M, (pic_width, pic_hight))\n",
        "        point_limit(right_point)\n",
        "        point_limit(heigth_point)\n",
        "        point_limit(new_left_point)\n",
        "        card_img = dst[int(right_point[1]):int(heigth_point[1]), int(new_left_point[0]):int(right_point[0])]\n",
        "        card_imgs.append(card_img)\n",
        "        #cv2.imshow(\"card\", card_img)\n",
        "        #cv2.waitKey(0)\n",
        "#开始使用颜色定位，排除不是车牌的矩形，目前只识别蓝、绿、黄车牌\n",
        "colors = []\n",
        "for card_index,card_img in enumerate(card_imgs):\n",
        "    green = yello = blue = black = white = 0\n",
        "    card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "    #有转换失败的可能，原因来自于上面矫正矩形出错\n",
        "    if card_img_hsv is None:\n",
        "        continue\n",
        "    row_num, col_num= card_img_hsv.shape[:2]\n",
        "    card_img_count = row_num * col_num\n",
        "\n",
        "    for i in range(row_num):\n",
        "        for j in range(col_num):\n",
        "            H = card_img_hsv.item(i, j, 0)\n",
        "            S = card_img_hsv.item(i, j, 1)\n",
        "            V = card_img_hsv.item(i, j, 2)\n",
        "            if 11 < H <= 34 and S > 34:#图片分辨率调整\n",
        "                yello += 1\n",
        "            elif 35 < H <= 99 and S > 34:#图片分辨率调整\n",
        "                green += 1\n",
        "            elif 99 < H <= 124 and S > 34:#图片分辨率调整\n",
        "                blue += 1\n",
        "            \n",
        "            if 0 < H <180 and 0 < S < 255 and 0 < V < 46:\n",
        "                black += 1\n",
        "            elif 0 < H <180 and 0 < S < 43 and 221 < V < 225:\n",
        "                white += 1\n",
        "    color = \"no\"\n",
        "\n",
        "    limit1 = limit2 = 0\n",
        "    if yello*2 >= card_img_count:\n",
        "        color = \"yello\"\n",
        "        limit1 = 11\n",
        "        limit2 = 34#有的图片有色偏偏绿\n",
        "    elif green*2 >= card_img_count:\n",
        "        color = \"green\"\n",
        "        limit1 = 35\n",
        "        limit2 = 99\n",
        "    elif blue*2 >= card_img_count:\n",
        "        color = \"blue\"\n",
        "        limit1 = 100\n",
        "        limit2 = 124#有的图片有色偏偏紫\n",
        "    elif black + white >= card_img_count*0.7:#TODO\n",
        "        color = \"bw\"\n",
        "    print(color)\n",
        "    colors.append(color)\n",
        "    print(blue, green, yello, black, white, card_img_count)\n",
        "    #cv2.imshow(\"color\", card_img)\n",
        "    #cv2.waitKey(0)\n",
        "    if limit1 == 0:\n",
        "        continue\n",
        "    #以上为确定车牌颜色\n",
        "    #以下为根据车牌颜色再定位，缩小边缘非车牌边界\n",
        "    xl, xr, yh, yl = accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "    if yl == yh and xl == xr:\n",
        "        continue\n",
        "    need_accurate = False\n",
        "    if yl >= yh:\n",
        "        yl = 0\n",
        "        yh = row_num\n",
        "        need_accurate = True\n",
        "    if xl >= xr:\n",
        "        xl = 0\n",
        "        xr = col_num\n",
        "        need_accurate = True\n",
        "    card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "    if need_accurate:#可能x或y方向未缩小，需要再试一次\n",
        "        card_img = card_imgs[card_index]\n",
        "        card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "        xl, xr, yh, yl = accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "        if yl == yh and xl == xr:\n",
        "            continue\n",
        "        if yl >= yh:\n",
        "            yl = 0\n",
        "            yh = row_num\n",
        "        if xl >= xr:\n",
        "            xl = 0\n",
        "            xr = col_num\n",
        "    card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "#以上为车牌定位\n",
        "#以下为识别车牌中的字符\n",
        "predict_result = []\n",
        "roi = None\n",
        "card_color = None\n",
        "for i, color in enumerate(colors):\n",
        "    if color in (\"blue\", \"yello\", \"green\"):\n",
        "        card_img = card_imgs[i]\n",
        "        gray_img = cv2.cvtColor(card_img, cv2.COLOR_BGR2GRAY)\n",
        "        #黄、绿车牌字符比背景暗、与蓝车牌刚好相反，所以黄、绿车牌需要反向\n",
        "        if color == \"green\" or color == \"yello\":\n",
        "            gray_img = cv2.bitwise_not(gray_img)\n",
        "        ret, gray_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "print(gray_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeOZqmFFgfPl",
        "outputId": "7cfeebd5-5304-4eef-9aa1-0c003b5d81d5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h,w: 300 521\n",
            "len(contours) 1\n",
            "0\n",
            "精确定位\n",
            "[[  0   0   0 ... 255   0   0]\n",
            " [  0   0   0 ... 255 255 255]\n",
            " [  0   0   0 ...   0 255 255]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VTYNjr88ee0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}