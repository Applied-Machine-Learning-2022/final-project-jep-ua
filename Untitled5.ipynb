{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKX0K42+VUyYxtLmRkc76I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Applied-Machine-Learning-2022/final-project-jep-ua/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract==0.3.9 \n",
        "!pip install imutils\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q6idzHyT4Oe0",
        "outputId": "6ab7b7c8-0dbd-422a-b849-e542819da874"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 5s (906 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytesseract==0.3.9\n",
            "  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract==0.3.9) (21.3)\n",
            "Collecting Pillow>=8.0.0\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 26.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract==0.3.9) (3.0.9)\n",
            "Installing collected packages: Pillow, pytesseract\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.2.0 pytesseract-0.3.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (9.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the data to train the model\n",
        "! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d andrewmvd/car-plate-detection\n",
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuezNDk97Nwc",
        "outputId": "f21a3eea-e34c-49ad-bf56-a34cbacba4fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading car-plate-detection.zip to /content\n",
            " 99% 201M/203M [00:01<00:00, 168MB/s]\n",
            "100% 203M/203M [00:01<00:00, 124MB/s]\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('car-plate-detection.zip','r') as z:\n",
        "  z.extractall('./')\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cZuzs4iBBPo",
        "outputId": "60966044-34c0-4cf1-bad7-f92e679d7372"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'images',\n",
              " 'annotations',\n",
              " '.ipynb_checkpoints',\n",
              " 'car-plate-detection.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "(train_images, train_labels), (test_images, test_labels) = \n",
        "\n"
      ],
      "metadata": {
        "id": "LEE0Y2PCAfqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  \".\",\n",
        "  validation_split=0.3,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  batch_size=32,\n",
        "  shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "for image_batch, labels_batch in ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9cmpUAgIWP9",
        "outputId": "b1c2676c-2a5b-411d-e5cd-2640ce0fc0e4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 433 files belonging to 5 classes.\n",
            "Using 304 files for training.\n",
            "(32, 256, 256, 3)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "433 * 0.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9OTRt_4JxTU",
        "outputId": "60424113-b4d9-4f8b-92a1-73245ad8656f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "303.09999999999997"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "s = set()\n",
        "for i in range(433):\n",
        "  s.add(cv2.imread(\"images/Cars{}.png\".format(i)).shape)\n",
        "\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzNHLflIdqf",
        "outputId": "5b6168b9-58d1-4570-f606-3d5a856ac449"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(141, 400, 3),\n",
              " (151, 400, 3),\n",
              " (176, 400, 3),\n",
              " (185, 400, 3),\n",
              " (190, 400, 3),\n",
              " (192, 400, 3),\n",
              " (196, 400, 3),\n",
              " (197, 400, 3),\n",
              " (198, 400, 3),\n",
              " (200, 400, 3),\n",
              " (201, 400, 3),\n",
              " (204, 400, 3),\n",
              " (205, 400, 3),\n",
              " (209, 400, 3),\n",
              " (210, 400, 3),\n",
              " (215, 400, 3),\n",
              " (218, 400, 3),\n",
              " (220, 415, 3),\n",
              " (221, 400, 3),\n",
              " (223, 300, 3),\n",
              " (225, 300, 3),\n",
              " (225, 400, 3),\n",
              " (226, 400, 3),\n",
              " (227, 323, 3),\n",
              " (229, 558, 3),\n",
              " (230, 400, 3),\n",
              " (232, 500, 3),\n",
              " (233, 400, 3),\n",
              " (234, 500, 3),\n",
              " (238, 400, 3),\n",
              " (240, 400, 3),\n",
              " (242, 400, 3),\n",
              " (242, 431, 3),\n",
              " (243, 400, 3),\n",
              " (244, 400, 3),\n",
              " (245, 400, 3),\n",
              " (246, 400, 3),\n",
              " (247, 400, 3),\n",
              " (248, 400, 3),\n",
              " (250, 400, 3),\n",
              " (251, 400, 3),\n",
              " (253, 400, 3),\n",
              " (255, 400, 3),\n",
              " (256, 400, 3),\n",
              " (259, 400, 3),\n",
              " (260, 320, 3),\n",
              " (260, 400, 3),\n",
              " (262, 400, 3),\n",
              " (262, 508, 3),\n",
              " (263, 350, 3),\n",
              " (265, 400, 3),\n",
              " (266, 400, 3),\n",
              " (267, 400, 3),\n",
              " (268, 400, 3),\n",
              " (268, 500, 3),\n",
              " (270, 400, 3),\n",
              " (270, 450, 3),\n",
              " (270, 471, 3),\n",
              " (275, 553, 3),\n",
              " (276, 320, 3),\n",
              " (279, 400, 3),\n",
              " (281, 400, 3),\n",
              " (284, 400, 3),\n",
              " (286, 430, 3),\n",
              " (288, 400, 3),\n",
              " (290, 400, 3),\n",
              " (290, 435, 3),\n",
              " (291, 400, 3),\n",
              " (292, 400, 3),\n",
              " (295, 400, 3),\n",
              " (299, 400, 3),\n",
              " (299, 450, 3),\n",
              " (300, 400, 3),\n",
              " (300, 467, 3),\n",
              " (300, 500, 3),\n",
              " (301, 400, 3),\n",
              " (303, 517, 3),\n",
              " (305, 400, 3),\n",
              " (307, 400, 3),\n",
              " (314, 236, 3),\n",
              " (315, 560, 3),\n",
              " (318, 400, 3),\n",
              " (319, 400, 3),\n",
              " (320, 400, 3),\n",
              " (331, 585, 3),\n",
              " (331, 586, 3),\n",
              " (332, 400, 3),\n",
              " (332, 443, 3),\n",
              " (333, 442, 3),\n",
              " (338, 600, 3),\n",
              " (342, 400, 3),\n",
              " (343, 590, 3),\n",
              " (350, 590, 3),\n",
              " (353, 400, 3),\n",
              " (354, 400, 3),\n",
              " (360, 480, 3),\n",
              " (365, 500, 3),\n",
              " (367, 400, 3),\n",
              " (367, 550, 3),\n",
              " (374, 500, 3),\n",
              " (375, 500, 3),\n",
              " (375, 600, 3),\n",
              " (380, 500, 3),\n",
              " (388, 507, 3),\n",
              " (398, 530, 3),\n",
              " (399, 600, 3),\n",
              " (400, 225, 3),\n",
              " (400, 240, 3),\n",
              " (400, 282, 3),\n",
              " (400, 300, 3),\n",
              " (400, 301, 3),\n",
              " (400, 370, 3),\n",
              " (400, 386, 3),\n",
              " (400, 399, 3),\n",
              " (400, 400, 3),\n",
              " (400, 500, 3),\n",
              " (400, 600, 3),\n",
              " (411, 600, 3),\n",
              " (416, 555, 3),\n",
              " (417, 600, 3),\n",
              " (420, 560, 3),\n",
              " (422, 457, 3),\n",
              " (424, 520, 3),\n",
              " (425, 600, 3),\n",
              " (450, 600, 3),\n",
              " (478, 400, 3),\n",
              " (500, 375, 3),\n",
              " (531, 600, 3)}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "\n",
        "image = cv2.imread(\"license_plate.jpg\")\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"/usr/bin/tesseract\" #r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# Grayscale, Gaussian blur, Otsu's threshold\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "# Morph open to remove noise and invert image\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "invert = 255 - opening\n",
        "\n",
        "# Perform text extraction\n",
        "data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "print(data)\n",
        "\n",
        "cv2.imwrite(\"thresh.jpg\", thresh)\n",
        "# cv2.imshow('thresh', thresh)\n",
        "# cv2.imshow('opening', opening)\n",
        "# cv2.imshow('invert', invert)\n",
        "cv2.waitKey()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKXm5vBcgHdl",
        "outputId": "1baf115c-aaaa-4989-8024-4223b657df93"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "» * Arkansas’ ii\n",
            "514 KZE\n",
            "\f\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! which tesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQpsL-TGgms1",
        "outputId": "a2ca3a76-f56c-4ae6-b1a1-571cd6ff0e56"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/tesseract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5GaGturVm-79"
      },
      "outputs": [],
      "source": [
        "#read in frames\n",
        "# import cv2 as cv\n",
        "# import pytesseract\n",
        "# cars_video = cv.VideoCapture('cars.mp4')\n",
        "\n",
        "\n",
        "# height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "# width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "# fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "# total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# cars_video = cv.VideoCapture('cars.mp4')\n",
        "\n",
        "# total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# frames_read = 0\n",
        "\n",
        "# for current_frame in range(0, total_frames):\n",
        "#   cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "#   ret, _ = cars_video.read()\n",
        "#   if not ret:\n",
        "#     raise Exception(f'Problem reading frame {current_frame} from video')\n",
        "#   if (current_frame+1) % 50 == 0:\n",
        "#     print(f'Read {current_frame+1} frames so far')\n",
        "\n",
        "# cars_video.release()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pytesseract\n",
        "# image = cv.imread(\"license_plate.jpg\")\n",
        "\n",
        "# image = Image.open(\"HT_ArkansasTag.png\")\n",
        "# image = Image.new(\"P\", (100, 100))\n",
        "# image= np.zeros((1, 1, 100))\n",
        "# pytesseract.image_to_string(image)\n",
        "\n",
        "# import cv2\n",
        "# image = cv2.imread(\"HT_ArkansasTag.png\")\n",
        "# image = cv2.resize(image, (600, 360))\n",
        "# words = pytesseract.image_to_string(image)\n",
        "# image.shape\n",
        "# print(words)\n",
        "\n",
        "# gray_image = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# gray_image = cv2.bilateralFilter(gray_image,11,17,17)\n",
        "\n",
        "# edged = cv2.Canny(gray_image,30,200)\n",
        "# cnts,new = cv2.findContours(edged.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
        "# # image = Image.open(\"license_plate.jpg\")\n",
        "# cnts = sorted(cnts,key = cv2.contourArea,reverse = True) [:30]\n",
        "# screenCnt = None\n",
        "\n",
        "# #Finding the contour with four sides\n",
        "# i=7\n",
        "# for c in cnts:\n",
        "#   perimeter = cv2.arcLength(c,True)\n",
        "#   approx = cv2.approxPolyDP(c,0.018*perimeter,True)\n",
        "#   if len(approx)==4:\n",
        "#     screenCnt = approx\n",
        "\n",
        "# x,y,w,h = cv2.boundingRect(c)\n",
        "# new_img = image[y:y+h,x:x+w]\n",
        "# cv2.imwrite('./'+str(i)+'.png',new_img)\n",
        "\n",
        "image = cv2.imread(\"license_plate.jpg\")\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "# Grayscale, Gaussian blur, Otsu's threshold\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "# Morph open to remove noise and invert image\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "invert = 255 - opening\n",
        "\n",
        "# Perform text extraction\n",
        "data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "print(data)\n",
        "\n",
        "cv2.imwrite(\"thresh.jpg\", thresh)\n",
        "# cv2.imshow('thresh', thresh)\n",
        "# cv2.imshow('opening', opening)\n",
        "# cv2.imshow('invert', invert)\n",
        "cv2.waitKey()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "aTyHKlgN39_m",
        "outputId": "b16c6146-d1e4-4f9a-c125-c6052471514e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TesseractNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe': 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-327a3151c02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Perform text extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--psm 6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     }[output_type]()\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     }[output_type]()\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    284\u001b[0m         }\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_filename_base'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextsep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m: C:\\Program Files\\Tesseract-OCR\\tesseract.exe is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "file_name = 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz'\n",
        "\n",
        "url = base_url + file_name\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "dir_name = file_name[0:-len('.tar.gz')]\n",
        "\n",
        "if os.path.exists(dir_name):\n",
        "  shutil.rmtree(dir_name) \n",
        "\n",
        "tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "\n",
        "os.listdir(dir_name)\n",
        "\n",
        "frozen_graph = os.path.join(dir_name, 'frozen_inference_graph.pb')\n",
        "\n",
        "with tf.io.gfile.GFile(frozen_graph, \"rb\") as f:\n",
        "  graph_def = tf.compat.v1.GraphDef()\n",
        "  loaded = graph_def.ParseFromString(f.read())\n",
        "\n",
        "cars_video = cv.VideoCapture('cars.mp4')\n",
        "height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "frames_read = 0\n",
        "\n",
        "r = 255\n",
        "g = 0\n",
        "b = 0\n",
        "scale = .5\n",
        "thickness = 1\n",
        "\n",
        "outputs = (\n",
        "  'num_detections:0',\n",
        "  'detection_classes:0',\n",
        "  'detection_scores:0',\n",
        "  'detection_boxes:0',\n",
        ")\n",
        "\n",
        "def wrap_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "  wrapped = tf.compat.v1.wrap_function(\n",
        "    lambda: tf.compat.v1.import_graph_def(graph_def, name=\"\"), [])\n",
        "\n",
        "  return wrapped.prune(\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n",
        "\n",
        "\n",
        "model = wrap_graph(graph_def=graph_def,\n",
        "                   inputs=[\"image_tensor:0\"],\n",
        "                   outputs=outputs)\n",
        "model.outputs\n",
        "\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "while (True):\n",
        "  # cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "  ret, image = cars_video.read()\n",
        "  if (not ret):\n",
        "    break \n",
        "  image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "  h, w, _ = image.shape\n",
        "  input_images = [image]\n",
        "  tensor = tf.convert_to_tensor(input_images, dtype=tf.uint8)\n",
        "\n",
        "  detections = model(tensor)\n",
        "\n",
        "  for i, box in enumerate(detections[3][0]):\n",
        "    if detections[1][0][i] == 18:\n",
        "       x1, y1, x2, y2 = int(box[1]*w), int(box[0]*h), int(box[3]*w), int(box[2]*h)\n",
        "       car = image[y1:y2, x1:x2]\n",
        "\n",
        "       gray = cv2.cvtColor(car, cv2.COLOR_RGB2GRAY)\n",
        "       blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "       thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "       \n",
        "       # Morph open to remove noise and invert image\n",
        "       kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "       opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "       invert = 255 - opening\n",
        "       \n",
        "       # Perform text extraction\n",
        "       data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "       if data ==[]:\n",
        "         continue\n",
        "       else:\n",
        "        print(data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8fgNAdVBjn3",
        "outputId": "0c74227a-6add-4e3e-f6f7-7e2b146d502a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile('License-Plate-Recognition-master.zip','r') as z:\n",
        "  z.extractall('./')\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiEJP3Ef7oJo",
        "outputId": "9ba07177-76b9-4801-eefd-3685be9e7759"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'License-Plate-Recognition-master.zip',\n",
              " 'predict.py',\n",
              " 'License-Plate-Recognition-master',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd License-Plate-Recognition-master; python predict.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W34m0cFmJaYv",
        "outputId": "fdb0c09a-fa98-40e9-af4c-f477f18da836"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"predict.py\", line 544, in <module>\n",
            "    r, roi, color = c.predict(\"2.jpg\")\n",
            "  File \"predict.py\", line 245, in predict\n",
            "    img = imreadex(car_pic)\n",
            "  File \"predict.py\", line 14, in imreadex\n",
            "    return cv2.imdecode(np.fromfile(filename, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '2.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/License-Plate-Recognition-master\")\n",
        "from predict import *"
      ],
      "metadata": {
        "id": "oc4eOeDdKF-6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV26hnqXfiCn",
        "outputId": "331e2f2c-182c-4aed-b7be-fac38059709a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car.jpeg     License-Plate-Recognition-master\t   __pycache__\n",
            "images.jpeg  License-Plate-Recognition-master.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from predict import *\n",
        "from google.colab.patches import cv2_imshow\n",
        "c = CardPredictor()\n",
        "gray_img = c.predict('/content/License-Plate-Recognition-master/test/car5.jpg')\n",
        "# cv2_imshow('ec.png', plate_img[1])\n",
        "# cv2_imshow(plate_img[1])\n",
        "# plate_img[3].shape\n",
        "import matplotlib.pyplot as plt\n",
        "cv2_imshow(gray_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XXo8xO8efERM",
        "outputId": "b5acf129-5066-4a71-b69a-772eadf68091"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h,w: 300 521\n",
            "len(contours) 3\n",
            "2\n",
            "精确定位\n",
            "blue\n",
            "3413 136 16 642 0 4418\n",
            "no\n",
            "4188 98 86 520 306 22599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function CardPredictor.__del__ at 0x7f33d736add0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/License-Plate-Recognition-master/predict.py\", line 147, in __del__\n",
            "  File \"/content/License-Plate-Recognition-master/predict.py\", line 202, in save_traindata\n",
            "AttributeError: 'CardPredictor' object has no attribute 'model'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=85x33 at 0x7F33D6C5FB90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFUAAAAhCAAAAACNLbhRAAABSElEQVR4nK2WSRbEIAhEKV/uf2V6YSJTqRmaTdI2fgtEDOQ/pu4dgn+hgr2gTlkXTvfUFUNEoFKl6fEE4fSsPfAZxOLFTN/thGvw7WuMDCA6PrIi93gia45SDD0KkSZgaYkrqfL3k+MeTmu1yPTC1I8Ob02DrSKTmiCmZFxLAuGpIcq6VJy1GzuMww9aPzsmeF26pzWvU7nQvHl7a+c08U9igNyXeua1V9enrhisUzXFnrOgqrQu19S1xbRPuS4/gwr7L1vKDPHIQxd1edc86V+i4jOwvThEhDUNNv+iztOV6LizY363XNmyibsbzD37ibV7ZlPozEFPFmzlfc/yYuhpJj+bLbcI0UIpPojwvp28axOmiUpdA6TXNTKNaKmysKq2ZhNGtqOXYwFYFKwz17WNEj89XrSyFvWU8LZGK2Y0lbcfBcKC+QETaWZL8SUl7QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract==0.3.9 \n",
        "!pip install imutils\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "id": "aBCCaI-UKVdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Code\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy\n",
        "import cv2\n",
        "import pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import os\n",
        "import tarfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from numpy.linalg import norm\n",
        "import sys\n",
        "import  os\n",
        "import json\n",
        "\n",
        "\n",
        "SZ  =  20           #training picture length and width\n",
        "MAX_WIDTH  =  1000 #Original  image maximum width\n",
        "Min_Area  =  2000 #The   maximum allowable area of ​​the license plate area\n",
        "PROVINCE_START = 1000\n",
        "\n",
        "\n",
        "base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "file_name = 'ssd_mobilenet_v1_coco_2018_01_28.tar.gz'\n",
        "\n",
        "url = base_url + file_name\n",
        "\n",
        "urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "dir_name = file_name[0:-len('.tar.gz')]\n",
        "\n",
        "if os.path.exists(dir_name):\n",
        "  shutil.rmtree(dir_name) \n",
        "\n",
        "tarfile.open(file_name, 'r:gz').extractall('./')\n",
        "\n",
        "os.listdir(dir_name)\n",
        "\n",
        "frozen_graph = os.path.join(dir_name, 'frozen_inference_graph.pb')\n",
        "\n",
        "with tf.io.gfile.GFile(frozen_graph, \"rb\") as f:\n",
        "  graph_def = tf.compat.v1.GraphDef()\n",
        "  loaded = graph_def.ParseFromString(f.read())\n",
        "\n",
        "cars_video = cv.VideoCapture('cars.mp4')\n",
        "height = int(cars_video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(cars_video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "fps = cars_video.get(cv.CAP_PROP_FPS)\n",
        "total_frames = int(cars_video.get(cv.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "frames_read = 0\n",
        "\n",
        "r = 255\n",
        "g = 0\n",
        "b = 0\n",
        "scale = .5\n",
        "thickness = 1\n",
        "\n",
        "outputs = (\n",
        "  'num_detections:0',\n",
        "  'detection_classes:0',\n",
        "  'detection_scores:0',\n",
        "  'detection_boxes:0',\n",
        ")\n",
        "\n",
        "def wrap_graph(graph_def, inputs, outputs, print_graph=False):\n",
        "  wrapped = tf.compat.v1.wrap_function(\n",
        "    lambda: tf.compat.v1.import_graph_def(graph_def, name=\"\"), [])\n",
        "\n",
        "  return wrapped.prune(\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n",
        "    tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n",
        "\n",
        "\n",
        "model = wrap_graph(graph_def=graph_def,\n",
        "                   inputs=[\"image_tensor:0\"],\n",
        "                   outputs=outputs)\n",
        "model.outputs\n",
        "\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "while (True):\n",
        "  # cars_video.set(cv.CAP_PROP_POS_FRAMES, current_frame)\n",
        "  ret, img = cars_video.read()\n",
        "  if (not ret):\n",
        "    break \n",
        "  img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  h, w, _ = image.shape\n",
        "  input_images = [img]\n",
        "  tensor = tf.convert_to_tensor(input_images, dtype=tf.uint8)\n",
        "\n",
        "  detections = model(tensor)\n",
        "\n",
        "  for i, box in enumerate(detections[3][0]):\n",
        "    if detections[1][0][i] == 18:\n",
        "      car_license_plate = gray_img\n",
        "      kernel = np.ones((20, 20), np.uint8)\n",
        "      img_opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
        "      img_opening = cv2.addWeighted(img, 1, img_opening, -1, 0);\n",
        "\n",
        "      #find the edge of the image\n",
        "      ret, img_thresh = cv2.threshold(img_opening, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "      img_edge = cv2.Canny(img_thresh, 100, 200)\n",
        "      #Use the opening and closing operations to make the image edges a whole\n",
        "      kernel = np.ones((self.cfg[\"morphologyr\"], self.cfg[\"morphologyc\"]), np.uint8)\n",
        "      img_edge1 = cv2.morphologyEx(img_edge, cv2.MORPH_CLOSE, kernel)\n",
        "      img_edge2 = cv2.morphologyEx(img_edge1, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "      #Find the rectangular area formed by the overall edge of the image, there may be many, and the license plate is in one of the rectangular areas\n",
        "      try:\n",
        "\t      contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      except ValueError:\n",
        "\t      image, contours, hierarchy = cv2.findContours(img_edge2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      contours = [cnt for cnt in contours if cv2.contourArea(cnt) > Min_Area]\n",
        "      print('len(contours)', len(contours))\n",
        "      #Exclude rectangular areas that are not license plates one by one\n",
        "      car_contours = []\n",
        "      for cnt in contours:\n",
        "\t      rect = cv2.minAreaRect(cnt)\n",
        "\t      area_width, area_height = rect[1]\n",
        "        if area_width < area_height:\n",
        "\t\t      area_width, area_height = area_height, area_width\n",
        "\t        wh_ratio = area_width / area_height\n",
        "\t      #print(wh_ratio)\n",
        "\t      #Required that the aspect ratioof the rectangular area is between 2 and 5.5, 2 to 5.5 is the aspect ratio of the license plate, and the rest of the rectangles are excluded\n",
        "          if wh_ratio > 2 and wh_ratio < 5.5:\n",
        "\t\t        car_contours.append(rect)\n",
        "\t\t        box = cv2.boxPoints(rect)\n",
        "\t\t        box = np.int0(box)\n",
        "\t\t#oldimg = cv2.drawContours(oldimg, [box], 0, (0, 0, 255), 2)\n",
        "\t\t#cv2.imshow(\"edge4\", oldimg)\n",
        "\t\t#cv2.waitKey(0)\n",
        "\n",
        "      print(len(car_contours))\n",
        "\n",
        "      print ( \"Precise Position\" )\n",
        "      card_imgs = []\n",
        "      # The rectangle area may be a slanted rectangle and needs to be corrected in order to use color positioning\n",
        "      for rect in car_contours:\n",
        "\t      if  rect [ 2 ] >  - 1  and  rect [ 2 ] <  1 : #Create angles so that left, high, right, and low get the correct values\n",
        "\t\t      angle = 1\n",
        "\t      else:\n",
        "\t\t      angle = rect[2]\n",
        "\t      rect  = ( rect [ 0 ], ( rect [ 1 ][ 0 ] + 5 , rect [ 1 ][ 1 ] + 5 ), angle ) # Expand the range to avoid the edge of the license plate from being excluded\n",
        "\n",
        "\t      box = cv2.boxPoints(rect)\n",
        "\t      heigth_point = right_point = [0, 0]\n",
        "\t      left_point = low_point = [pic_width, pic_hight]\n",
        "        for point in box:\n",
        "          if left_point[0] > point[0]:\n",
        "\t\t\t      left_point = point\n",
        "\t\t      if low_point[1] > point[1]:\n",
        "\t\t\t      low_point = point\n",
        "\t\t      if heigth_point[1] < point[1]:\n",
        "\t\t\t      heigth_point = point\n",
        "\t\t      if right_point[0] < point[0]:\n",
        "\t\t\t      right_point = point\n",
        "\n",
        "        if  left_point [ 1 ] <=  right_point [ 1 ]: #positive angle\n",
        "\t\t      new_right_point = [right_point[0], heigth_point[1]]\n",
        "\t\t      pts2  =  np . float32 ([ left_point , height_point , new_right_point ]) #Character just height needs to be changed\n",
        "\t\t      pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "\t\t      M = cv2.getAffineTransform(pts1, pts2)\n",
        "\t\t      dst = cv2.warpAffine(i got, M, (pic_width, pic_hight))\n",
        "\t\t      point_limit(new_right_point)\n",
        "\t\t      point_limit(heigth_point)\n",
        "\t\t      point_limit(left_point)\n",
        "\t\t      card_img = dst[int(left_point[1]):int(heigth_point[1]), int(left_point[0]):int(new_right_point[0])]\n",
        "\t\t      card_imgs.append(card_img)\n",
        "\t\t      #cv2.imshow(\"card\", card_img)\n",
        "\t\t      #cv2.waitKey(0)\n",
        "\t      elif  left_point [ 1 ] >  right_point [ 1 ]: #negative angle\n",
        "\t\t\t\t\n",
        "\t\t      new_left_point = [left_point[0], heigth_point[1]]\n",
        "\t\t      pts2  =  np . float32 ([ new_left_point , height_point , right_point ]) #Character just height needs to be changed\n",
        "\t\t      pts1 = np.float32([left_point, heigth_point, right_point])\n",
        "\t\t      M = cv2.getAffineTransform(pts1, pts2)\n",
        "\t\t      dst = cv2.warpAffine(oldimg, M, (pic_width, pic_hight))\n",
        "\t\t      point_limit(right_point)\n",
        "\t\t      point_limit(heigth_point)\n",
        "          point_limit(new_left_point)\n",
        "\t\t      card_img = dst[int(right_point[1]):int(heigth_point[1]), int(new_left_point[0]):int(right_point[0])]\n",
        "\t\t      card_imgs.append(card_img)\n",
        "\t\t      #cv2.imshow(\"card\", card_img)\n",
        "\t\t      #cv2.waitKey(0)\n",
        "      #Start using color positioning, excluding rectangles that are not license plates, currently only blue, green, and yellow license plates are recognized\n",
        "      colors = []\n",
        "      for card_index,card_img in enumerate(card_imgs):\n",
        "\t      green = yello = blue = black = white = 0\n",
        "\t      card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "\t      #There is a possibility of conversion failure, the reason comes from the above correction rectangle error\n",
        "\t      if card_img_hsv is None:\n",
        "\t\t      continue\n",
        "\t      row_num, col_num= card_img_hsv.shape[:2]\n",
        "\t      card_img_count = row_num * col_num\n",
        "\n",
        "\t      for  i  in  range ( row_num ):\n",
        "\t\t      for  j  in  range ( col_num ):\n",
        "\t\t\t      H = card_img_hsv.item(i, j, 0)\n",
        "\t\t\t      S = card_img_hsv.item(i, j, 1)\n",
        "\t\t\t      V = card_img_hsv.item(i, j, 2)\n",
        "\t\t\t      if  11  <  H  <=  34  and  S  >  34 : #Image resolution adjustment\n",
        "\t\t\t\t      yello  +=  1\n",
        "\t\t\t      elif  35  <  H  <=  99  and  S  >  34 : #Image resolution adjustment\n",
        "\t\t\t\t      green += 1\n",
        "\t\t\t      elif  99  <  H  <=  124  and  S  >  34 : #Image resolution adjustment\n",
        "\t\t\t\t      blue += 1\n",
        "            if 0 < H <180 and 0 < S < 255 and 0 < V < 46:\n",
        "\t\t\t\t      black += 1\n",
        "\t\t\t      elif 0 < H <180 and 0 < S < 43 and 221 < V < 225:\n",
        "\t\t\t\t      white += 1\n",
        "\t      color = \"no\"\n",
        "\n",
        "\t      limit1  =  limit2  =  0\n",
        "\t      if yello*2 >= card_img_count:\n",
        "\t\t      color = \"yello\"\n",
        "\t\t      limit1 = 11\n",
        "\t\t      limit2  =  34 #Some pictures are greenish in color\n",
        "\t      elif green*2 >= card_img_count:\n",
        "\t\t      color = \"green\"\n",
        "\t\t      limit1 = 35\n",
        "\t\t      limit2  =  99\n",
        "\t      elif blue*2 >= card_img_count:\n",
        "\t\t      color = \"blue\"\n",
        "\t\t      limit1 = 100\n",
        "\t\t      limit2  =  124 #Some pictures are slightly purple in color\n",
        "\t      elif black + white >= card_img_count*0.7:#TODO\n",
        "\t\t      color = \"bw\"\n",
        "\t      print(color)\n",
        "\t      colors.append(color)\n",
        "\t      print(blue, green, yello, black, white, card_img_count)\n",
        "\t      #cv2.imshow(\"color\", card_img)\n",
        "\t      #cv2.waitKey(0)\n",
        "\t      if limit1 == 0:\n",
        "\t\t      continue\n",
        "\t      #The above is to determine the color of the license plate\n",
        "\t      #The following is to relocate according to the color of the license plate, and reduce the edge non-license plate boundary\n",
        "\t      xl, xr, yh, yl = self.accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "\t      if yl == yh and xl == xr:\n",
        "\t\t      continue\n",
        "\t      need_accurate = False\n",
        "\n",
        "        if yl >= yh:\n",
        "\t\t      yl = 0\n",
        "\t\t      yh = row_num\n",
        "\t\t      need_accurate = True\n",
        "\t      if xl >= xr:\n",
        "\t\t      xl = 0\n",
        "\t\t      xr = col_num\n",
        "\t\t      need_accurate = True\n",
        "\t      card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "\t\t\t\n",
        "        if  need_accurate : #Maybe the x or y direction is not reduced, you need to try again\n",
        "\t\t      card_img = card_imgs[card_index]\n",
        "\t\t      card_img_hsv = cv2.cvtColor(card_img, cv2.COLOR_BGR2HSV)\n",
        "\t\t      xl, xr, yh, yl = self.accurate_place(card_img_hsv, limit1, limit2, color)\n",
        "\t\t      if yl == yh and xl == xr:\n",
        "\t\t\t      continue\n",
        "\t\t      if yl >= yh:\n",
        "\t\t\t      yl = 0\n",
        "\t\t\t      yh = row_num\n",
        "\t\t      if xl >= xr:\n",
        "\t\t\t      xl = 0\n",
        "\t\t\t      xr = col_num\n",
        "\t      card_imgs[card_index] = card_img[yl:yh, xl:xr] if color != \"green\" or yl < (yh-yl)//4 else card_img[yl-(yh-yl)//4:yh, xl:xr]\n",
        "      for i, color in enumerate(colors):\n",
        "\t      if color in (\"blue\", \"yello\", \"green\"):\n",
        "\t\t      card_img = card_imgs[i]\n",
        "\t\t      gray_img = cv2.cvtColor(card_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t      #The characters of the yellow and green license plates are darker than the background and opposite to the blue license plates, so the yellow and green license plates need to be reversed\n",
        "\t\t      if color == \"green\" or color == \"yello\":\n",
        "\t\t\t      gray_img = cv2.bitwise_not(gray_img)\n",
        "\t\t      ret, gray_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "      car_license_plate = gray_img\n",
        "      gray = cv2.cvtColor(car_license_plate, cv2.COLOR_RGB2GRAY)\n",
        "      blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
        "      thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "       \n",
        "      # Morph open to remove noise and invert image\n",
        "      kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "      opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "      invert = 255 - opening\n",
        "       \n",
        "      # Perform text extraction\n",
        "      data = pytesseract.image_to_string(invert, lang='eng', config='--psm 6')\n",
        "      if data ==[]:\n",
        "        continue\n",
        "      else:\n",
        "      print(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "uCSKP1DLb0k9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}